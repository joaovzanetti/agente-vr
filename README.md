# Desafio 4 â€” **Agente VR Mensal** (LangChain + UI)

Este repositÃ³rio entrega um **agente em LangChain** (com UI em Streamlit) que:
- processa as planilhas de **entrada** (ATIVOS, FÃ‰RIAS/FERIAS, DESLIGADOS),
- aplica as **regras de elegibilidade** e o rateio **80/20** (80% empresa / 20% profissional),
- gera a planilha final `VR_MENSAL_MM_YYYY.xlsx`,
- cria a aba **ValidaÃ§Ãµes** (estrutura, 80/20, negativos).

> âœ… O agente foi projetado para rodar em trÃªs modos:  
> 1) **Streamlit (UI)** â€” com **OpenAI**, **Ollama** (local) ou **Fallback** (sem LLM)  
> 2) **CLI com OpenAI** (sem UI)  
> 3) **CLI com Ollama** (sem UI)

---

## ğŸ“‚ Estrutura esperada

```
desafio_vr_agente/
â”œâ”€â”€ agent_vr.py                  # Agente LangChain (ferramentas + orquestraÃ§Ã£o)
â”œâ”€â”€ steps.py                     # Pipeline de processamento (carregar, montar, exportar)
â”œâ”€â”€ utils.py                     # FunÃ§Ãµes auxiliares (normalizaÃ§Ã£o etc.)
â”œâ”€â”€ ui_streamlit_agent.py        # Interface web (Streamlit)
â”œâ”€â”€ requirements_agent.txt       # DependÃªncias
â”œâ”€â”€ README.md                    # ESTE arquivo
â”œâ”€â”€ entradas/                    # Insumos e modelo
â”‚   â”œâ”€â”€ ATIVOS.xlsx
â”‚   â”œâ”€â”€ FERIAS.xlsx     (ou FÃ‰RIAS.xlsx)
â”‚   â”œâ”€â”€ DESLIGADOS.xlsx
â”‚   â””â”€â”€ VR Mensal 05.2025.xlsx  # Modelo (aba de referÃªncia)
â””â”€â”€ (exemplo) VR_MENSAL_08_2025.xlsx
```

---

## ğŸ§° Requisitos

- Python 3.10+  
- Windows, macOS ou Linux  
- (Opcional) Conta e **OPENAI_API_KEY** vÃ¡lida **ou** **Ollama** instalado para rodar LLM local  
- `pip install -r requirements_agent.txt`

### InstalaÃ§Ã£o rÃ¡pida (Windows / PowerShell)
```powershell
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements_agent.txt
```

### InstalaÃ§Ã£o rÃ¡pida (macOS/Linux)
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements_agent.txt
```

---

## ğŸš€ Modos de execuÃ§Ã£o

### 1) **Streamlit (UI)**

Inicie a interface:
```powershell
.\.venv\Scripts\activate
streamlit run ui_streamlit_agent.py
```
A UI abre em `http://localhost:8501/` com **duas abas**:

- **ğŸ¤– Agente (LLM)** â€” usa LangChain + LLM (OpenAI ou Ollama)  
  Sidebar â†’ selecione o provedor: **openai**, **ollama** ou **auto**  
  - **OpenAI**: defina a chave antes:
    ```powershell
    setx OPENAI_API_KEY "sk-xxxxx"
    # feche e reabra o PowerShell
    ```
  - **Ollama**: tenha o serviÃ§o ativo e um modelo disponÃ­vel  
    ```powershell
    ollama pull qwen2:0.5b     # modelo leve (recomendado para mÃ¡quinas menos potentes)
    $env:OLLAMA_MODEL = "qwen2:0.5b"
    ```

## ğŸ”„ Modelos Ollama recomendados

O agente suporta execuÃ§Ã£o com **LLMs locais via Ollama**.  
VocÃª pode escolher o modelo conforme o hardware disponÃ­vel:

| Modelo           | Tamanho aprox. | RAM mÃ­nima recomendada | ObservaÃ§Ãµes |
|------------------|----------------|-------------------------|-------------|
| `qwen2:0.5b`     | ~0.5B params   | 3â€“4 GiB                | Muito leve, roda em PCs modestos. Pode ser lento e â€œalucinarâ€ em prompts longos. |
| `phi3:mini`      | ~3.8B params   | 6 GiB+                 | EquilÃ­brio entre leveza e qualidade. Recomendado se nÃ£o houver OpenAI. |
| `tinyllama:1.1b` | ~1.1B params   | 4â€“5 GiB                | Alternativa leve, desempenho similar ao qwen2. |
| `mistral:7b`     | ~7B params     | 8 GiB+                 | Mais robusto, resultados melhores. Requer mÃ¡quina mais forte. |
| `llama3:8b`      | ~8B params     | 10â€“12 GiB+             | Alta qualidade, prÃ³ximo do OpenAI em alguns casos. Necessita bastante memÃ³ria. |

### Comandos de instalaÃ§Ã£o
```bash
# Exemplo de pull para instalar modelos
ollama pull qwen2:0.5b
ollama pull phi3:mini
ollama pull tinyllama:1.1b
ollama pull mistral:7b
ollama pull llama3:8b

ApÃ³s o download, selecione o modelo a ser usado definindo a variÃ¡vel de ambiente:

$env:OLLAMA_MODEL = "qwen2:0.5b"



  **Exemplo de prompt (curto, recomendado):**
  ```
  Gere o VR de 08/2025 usando a pasta entradas com regra integral e salve como VR_MENSAL_08_2025.xlsx. Depois valide a planilha gerada usando o modelo entradas/VR Mensal 05.2025.xlsx.
  ```

  > âš ï¸ **Modelos muito pequenos (ex.: qwen2:0.5b)** podem ser **lentos** e Ã s vezes **nÃ£o seguir o ReAct** em tarefas longas.  
  > Se notar que â€œfinalizaâ€ sem executar ferramentas, rode em **duas etapas** (Gerar â†’ Validar).

- **ğŸ§° GeraÃ§Ã£o direta (fallback)** â€” roda **sem LLM**, apenas Python  
  Preencha: pasta de entradas, mÃªs/ano, nome do arquivo e **modelo** â†’ **Gerar** â†’ **Validar**.  
  Ãštil para ambientes sem chave ou sem Ollama.

---

### 2) **CLI com OpenAI** (sem UI)
```powershell
setx OPENAI_API_KEY "sk-xxxxx"
# feche e reabra o PowerShell
.\.venv\Scripts\activate
python .\agent_vr.py --llm openai --ask "Gere o VR de 08/2025 usando a pasta entradas com regra integral e valide com o modelo entradas/VR Mensal 05.2025.xlsx."
```

### 3) **CLI com Ollama** (sem UI)
```powershell
ollama pull qwen2:0.5b
$env:OLLAMA_MODEL = "qwen2:0.5b"
.\.venv\Scripts\activate
python .\agent_vr.py --llm ollama --ask "Gere o VR de 08/2025 usando a pasta entradas com regra integral e valide com o modelo entradas/VR Mensal 05.2025.xlsx."
```

> ğŸ’¡ Dica de testes â€œrÃ¡pidosâ€ com modelos pequenos (seguem ferramentas com 1 passo):
```powershell
python .\agent_vr.py --llm ollama --ask "Liste as colunas obrigatÃ³rias da aba ATIVOS"
python .\agent_vr.py --llm ollama --ask "Mostre a aba ValidaÃ§Ãµes do arquivo VR_MENSAL_08_2025.xlsx"
```

---

## ğŸ“„ SaÃ­da gerada

- **Arquivo**: `VR_MENSAL_MM_YYYY.xlsx`  
- **Abas**:
  - **VR Mensal** â€” com `DIAS`, `VALOR_DIARIO_VR`, `TOTAL`, `Custo empresa` (= 0.8*TOTAL), `Desconto profissional` (= 0.2*TOTAL)  
  - **ATIVOS**, **FERIAS**, **DESLIGADOS** â€” bases auxiliares (quando disponÃ­veis)  
  - **ValidaÃ§Ãµes** â€” checks automÃ¡ticos:
    - **Colunas faltantes/extras** (comparaÃ§Ã£o com o **modelo** `entradas/VR Mensal 05.2025.xlsx`)
    - **Regra 80/20** por linha e no somatÃ³rio
    - **Valores negativos** (TOTAL, Custo empresa, Desconto profissional)
    - DetecÃ§Ã£o opcional de â€œvalidaÃ§Ãµes de referÃªnciaâ€

> **Regra 80/20**: Ã© **aplicada e reforÃ§ada** automaticamente na aba â€œVR Mensalâ€.

---

## âœ… Como validar manualmente (dupla-checagem)

1) Abra `VR_MENSAL_MM_YYYY.xlsx` â†’ **VR Mensal**  
   - confira se `Custo empresa â‰ˆ TOTAL * 0,8`  
   - `Desconto profissional â‰ˆ TOTAL * 0,2`  

2) Abra **ValidaÃ§Ãµes**  
   - â€œ80/20: OKâ€  
   - Colunas faltantes/extras â†’ se houver, sÃ£o alertas informativos  
   - Valores negativos â†’ se apontar, geralmente vÃªm dos insumos (ex.: fÃ©rias acima do padrÃ£o)

---

## ğŸ§ª Notas para o avaliador

- O agente foi implementado com **LangChain (ReAct)** e ferramentas:
  - `gerar_vr_mensal` â€” processa insumos, aplica regras, exporta Excel  
  - `validar_conformidade` â€” compara estrutura com o **modelo** (aba â€œVR Mensalâ€), verifica 80/20, negativos, e preenche a aba **ValidaÃ§Ãµes**  
  - `ler_validacoes` â€” retorna o conteÃºdo da aba **ValidaÃ§Ãµes** em JSON  
  - `listar_colunas_obrigatorias` â€” lista o schema esperado por aba  

- O modo **Fallback (UI)** cumpre integralmente o objetivo **sem LLM** (Ãºtil caso nÃ£o haja chave ou hardware).

- **OpenAI** Ã© o caminho **recomendado** para o agente (rÃ¡pido e estÃ¡vel).  
  - PrÃ©-checagem (opcional):
    ```bash
    python - << 'PY'
from langchain_openai import ChatOpenAI
print(ChatOpenAI(model="gpt-4o-mini", temperature=0).invoke("ping").content)
PY
    ```
- **Ollama** funciona, mas:
  - modelos grandes exigem RAM (ex.: `llama3:8b` â‰ˆ 5â€“6 GiB livres),
  - modelos **muito pequenos** (ex.: `qwen2:0.5b`) podem **alucinar** em prompts longos; use prompts **curtos**.

---

## ğŸ§¯ Troubleshooting

- **`OPENAI_API_KEY` nÃ£o definida**  
  â†’ definir variÃ¡vel de ambiente e reabrir o terminal.

- **Ollama 404 / â€œmodel not foundâ€**  
  â†’ `ollama pull <modelo>` e `ollama list` para confirmar o nome.  
  â†’ defina `OLLAMA_MODEL`, ex.: `qwen2:0.5b`.

- **Ollama â€œconnection refusedâ€ (WinError 10061)**  
  â†’ inicie o serviÃ§o: `ollama serve`  
  â†’ se a porta 11434 estiver ocupada, mude:  
    ```powershell
    $env:OLLAMA_HOST = "127.0.0.1:11435"
    ollama serve -p 11435
    ```

- **Streamlit abre mas o agente â€œfinalizaâ€ sem agir**  
  â†’ Ã© limitaÃ§Ã£o do modelo tiny. Reenvie com prompts curtos **ou** use a ferramenta `pipeline_gerar_e_validar`.

- **Erro de arquivo nÃ£o encontrado**  
  â†’ confirme que `VR_MENSAL_MM_YYYY.xlsx` estÃ¡ na **raiz do projeto** ou passe o caminho completo.  
  â†’ nomes com espaÃ§os/parÃªnteses precisam estar exatos (ex.: `"VR_MENSAL_08_2025 (1).xlsx"`).

---

## ğŸ” ObservaÃ§Ãµes de privacidade

- O agente nÃ£o solicita nem exibe PII (CPF, etc.).  
- Arquivos Excel nÃ£o sÃ£o enviados a serviÃ§os externos no **Fallback** ou com **Ollama**.  
- No modo **OpenAI**, apenas o **texto dos prompts** e mensagens do agente sÃ£o enviados Ã  API â€” as planilhas sÃ£o processadas **localmente** pelo Python.

---

## ğŸ§¾ LicenÃ§a & CrÃ©ditos

Projeto desenvolvido para o **Desafio 4 â€“ Agente VR Mensal**.  
Tecnologias: **Python, LangChain, Streamlit, Pandas, OpenPyXL**.  
LLM: **OpenAI** (opcional) ou **Ollama** (local).

---

Qualquer dÃºvida de execuÃ§Ã£o, basta rodar o **Fallback** na UI para garantir a geraÃ§Ã£o/validaÃ§Ã£o local, e/ou usar **OpenAI** para testar o fluxo completo de agente com alto desempenho.
